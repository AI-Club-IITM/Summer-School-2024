{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial NB"
      ],
      "metadata": {
        "id": "GJ4zrP98rgZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4J4Vb2dnmPu",
        "outputId": "d932efb6-fe64-46b3-a5b8-4f30ca746504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9983\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Hockey - class 0\n",
        "# Space  - class 1\n",
        "\n",
        "# Load dataset (Dataset having sentences from hockey and space)\n",
        "df = pd.read_csv(\"newsgroups20.csv\")\n",
        "X, y = df[\"sentences\"], df[\"target\"]\n",
        "\n",
        "# Let the vocab be [\"is\", \"was\", \"that\"]\n",
        "# the count vectorizer will return [2, 0, 1] for \"that is is\" and [0, 1, 1] for \"that was\"\n",
        "\n",
        "# Convert text data to feature vectors\n",
        "vectorizer = CountVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create and train Multinomial Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To predict on new data\n",
        "new_data = [\"The hockey game was intense and exciting.\", \"The spacecraft successfully launched to Mars.\"]\n",
        "new_data_vec = vectorizer.transform(new_data)\n",
        "predictions = model.predict(new_data_vec)\n",
        "print(\"\\nPredictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL5ocLBVqo_T",
        "outputId": "41112b3a-2ddb-4a85-f4d7-613bafe07d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian NB"
      ],
      "metadata": {
        "id": "XB11Vjz8r772"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Iris dataset contains measurments from the flowers Setosa, Versicolour, and Virginica\n",
        "# The measurements are sepal length, sepal width, petal length and petal width\n",
        "# 0 - setosa\n",
        "# 1 - versicolor\n",
        "# 2 - virginica\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create and train Gaussian Naive Bayes model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_etPmqPr9N9",
        "outputId": "f32556de-f086-404b-a54b-0fb8246546b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To predict on new data\n",
        "new_data = [[5.1, 3.5, 1.4, 0.2], [6.7, 3.1, 4.7, 1.5]]\n",
        "predictions = model.predict(new_data)\n",
        "print(\"\\nPredictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI_GK8fzsGin",
        "outputId": "94698159-2559-4f26-94e1-ac246b56015e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions: [0 1]\n"
          ]
        }
      ]
    }
  ]
}